{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#0.import and random seeds\n"
      ],
      "metadata": {
        "id": "O6G1rRnYt22w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WhlcLeoVsyWt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.distributions as td\n",
        "import torch.utils.data\n",
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "import os\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "#dataset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)                           # Python built-in random module\n",
        "    np.random.seed(seed)                        # NumPy random generator\n",
        "    torch.manual_seed(seed)                     # PyTorch CPU random seed\n",
        "    torch.cuda.manual_seed(seed)                # PyTorch current GPU random seed\n",
        "    torch.cuda.manual_seed_all(seed)            # PyTorch all GPUs random seed\n",
        "    torch.backends.cudnn.deterministic = True   # Ensure deterministic behavior in cuDNN\n",
        "    torch.backends.cudnn.benchmark = False      # Disable auto-optimization to prevent non-deterministic behavior\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)    # Control hash-based randomness in Python\n",
        "\n",
        "set_seed(42)\n"
      ],
      "metadata": {
        "id": "OtQ3OkKP1FyY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.Dataset  \n",
        "just copy the code provided by the professor\n",
        "\n"
      ],
      "metadata": {
        "id": "4OuS5xx-nLi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def subsample(data, targets, num_data, num_classes):\n",
        "    idx = targets < num_classes  # Select samples with class labels less than num_classes (e.g., only classes 0, 1, 2)\n",
        "    new_data = data[idx][:num_data].unsqueeze(1).to(torch.float32) / 255  # Select the first num_data images and normalize to [0,1]\n",
        "    new_targets = targets[idx][:num_data]  # Select corresponding labels for the subsampled images\n",
        "    return torch.utils.data.TensorDataset(new_data, new_targets)  # Create a TensorDataset with the filtered images and labels\n",
        "\n",
        "num_train_data = 2048\n",
        "num_classes = 3\n",
        "\n",
        "train_tensors = datasets.MNIST(\n",
        "    \"data/\", train=True, download=True,\n",
        "    transform=transforms.Compose([transforms.ToTensor()])  # Convert images to tensors\n",
        ")\n",
        "\n",
        "test_tensors = datasets.MNIST(\n",
        "    \"data/\", train=False, download=True,\n",
        "    transform=transforms.Compose([transforms.ToTensor()])  # Convert images to tensors\n",
        ")\n",
        "train_data = subsample(\n",
        "    train_tensors.data, train_tensors.targets,\n",
        "    num_train_data, num_classes\n",
        ")\n",
        "test_data = subsample(\n",
        "    test_tensors.data, test_tensors.targets,\n",
        "    num_train_data, num_classes\n",
        ")\n",
        "\n",
        "batch_size=32\n",
        "mnist_train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size=batch_size, shuffle=True\n",
        ")\n",
        "mnist_test_loader = torch.utils.data.DataLoader(\n",
        "    test_data, batch_size=batch_size, shuffle=False\n",
        ")\n",
        "latent_dim=2\n",
        "M=latent_dim\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "1ul7SutXjtmn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.GaussianPrior and Encoder/Decoder\n",
        "Just copy the code provided by the professor\n"
      ],
      "metadata": {
        "id": "RKGEA5qGnR4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianPrior(nn.Module):\n",
        "    def __init__(self, M):\n",
        "        \"\"\"\n",
        "        Define a Gaussian prior distribution with zero mean and unit variance.\n",
        "\n",
        "                Parameters:\n",
        "        M: [int]\n",
        "           Dimension of the latent space.\n",
        "        \"\"\"\n",
        "        super(GaussianPrior, self).__init__()\n",
        "        self.M = M\n",
        "        self.mean = nn.Parameter(torch.zeros(self.M), requires_grad=False)\n",
        "        self.std = nn.Parameter(torch.ones(self.M), requires_grad=False)\n",
        "\n",
        "    def forward(self):\n",
        "        \"\"\"\n",
        "        Return the prior distribution.\n",
        "\n",
        "        Returns:\n",
        "        prior: [torch.distributions.Distribution]\n",
        "        \"\"\"\n",
        "        return td.Independent(td.Normal(loc=self.mean, scale=self.std), 1)\n",
        "\n",
        "class GaussianEncoder(nn.Module):\n",
        "    def __init__(self, encoder_net):\n",
        "        \"\"\"\n",
        "        Define a Gaussian encoder distribution based on a given encoder network.\n",
        "\n",
        "        Parameters:\n",
        "        encoder_net: [torch.nn.Module]\n",
        "            The encoder network that takes a tensor of dimension\n",
        "            `(batch_size, feature_dim1, feature_dim2)` as input\n",
        "            and outputs a tensor of dimension `(batch_size, 2M)`,\n",
        "            where M is the dimension of the latent space.\n",
        "        \"\"\"\n",
        "        super(GaussianEncoder, self).__init__()\n",
        "        self.encoder_net = encoder_net\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Given a batch of input data, return a Gaussian distribution over the latent space.\n",
        "\n",
        "        Parameters:\n",
        "        x: [torch.Tensor]\n",
        "            A tensor of dimension `(batch_size, feature_dim1, feature_dim2)`.\n",
        "\n",
        "        Returns:\n",
        "        A Gaussian distribution with computed mean and standard deviation.\n",
        "        \"\"\"\n",
        "        mean, std = torch.chunk(self.encoder_net(x), 2, dim=-1)\n",
        "        return td.Independent(td.Normal(loc=mean, scale=torch.exp(std)), 1)\n",
        "\n",
        "        # Example:\n",
        "        # z = torch.randn(4, 10)  # Assume z is a tensor of shape [batch_size=4, 10]\n",
        "        # a, b = torch.chunk(z, 2, dim=-1)\n",
        "        # a and b will have shape [4, 5], as the tensor is split into two parts along the last dimension.\n",
        "def new_encoder():\n",
        "        encoder_net = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
        "            nn.Softmax(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
        "            nn.Softmax(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512, 2 * M),\n",
        "        )\n",
        "        return encoder_net\n",
        "class GaussianDecoder(nn.Module):\n",
        "    def __init__(self, decoder_net):\n",
        "        \"\"\"\n",
        "        Define a Gaussian decoder distribution based on a given decoder network.\n",
        "\n",
        "        Parameters:\n",
        "        decoder_net: [torch.nn.Module]\n",
        "            The decoder network that takes a tensor of dimension `(batch_size, M)`\n",
        "            as input, where M is the dimension of the latent space, and outputs a\n",
        "            tensor of dimension `(batch_size, feature_dim1, feature_dim2)`.\n",
        "        \"\"\"\n",
        "        super(GaussianDecoder, self).__init__()\n",
        "        self.decoder_net = decoder_net\n",
        "        # self.std = nn.Parameter(torch.ones(28, 28) * 0.5, requires_grad=True)\n",
        "        # In case you want to learn the standard deviation of the Gaussian.\n",
        "\n",
        "    def forward(self, z):\n",
        "        \"\"\"\n",
        "        Given a batch of latent variables, return a Gaussian distribution over the data space.\n",
        "\n",
        "        Parameters:\n",
        "        z: [torch.Tensor]\n",
        "            A tensor of dimension `(batch_size, M)`, where M is the dimension of the latent space.\n",
        "\n",
        "        Returns:\n",
        "        A Gaussian distribution with computed mean and a fixed standard deviation.\n",
        "        \"\"\"\n",
        "        means = self.decoder_net(z)\n",
        "        return td.Independent(td.Normal(loc=means, scale=1e-1), 3) #note the variance of decoder is fixed\n",
        "        # This defines a 784-dimensional independent normal distribution, where each dimension is independent.\n",
        "def new_decoder():\n",
        "        decoder_net = nn.Sequential(\n",
        "            nn.Linear(M, 512),\n",
        "            nn.Unflatten(-1, (32, 4, 4)),\n",
        "            nn.Softmax(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ConvTranspose2d(32, 32, 3, stride=2, padding=1, output_padding=0),\n",
        "            nn.Softmax(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Softmax(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
        "        )\n",
        "        return decoder_net"
      ],
      "metadata": {
        "id": "4Ewa8X8LuVcS"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.VAE\n",
        "having changed the provided code ,so that for each mini-batch of data, we randomly sample a decoder and take a gradient step to optimize the ELBO\n"
      ],
      "metadata": {
        "id": "G3nNIR4xoM5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, prior, decoders, encoder):\n",
        "        \"\"\"\n",
        "        Variational Autoencoder (VAE) with multiple decoders.\n",
        "\n",
        "        Parameters:\n",
        "        prior: [torch.nn.Module]\n",
        "            The prior distribution over the latent space.\n",
        "        decoders: [list of torch.nn.Module]\n",
        "            A list containing multiple decoders.\n",
        "        encoder: [torch.nn.Module]\n",
        "            The encoder network that maps input data to a latent distribution.\n",
        "        \"\"\"\n",
        "        super(VAE, self).__init__()\n",
        "        self.prior = prior\n",
        "        self.decoders = nn.ModuleList(decoders)  # Use ModuleList to allow PyTorch to properly track parameters\n",
        "        self.encoder = encoder\n",
        "\n",
        "    def elbo(self, x, decoder_idx):\n",
        "        \"\"\"\n",
        "        Compute the Evidence Lower Bound (ELBO) for a given input and selected decoder.\n",
        "\n",
        "        Parameters:\n",
        "        x: [torch.Tensor]\n",
        "            The input data tensor.\n",
        "        decoder_idx: [int]\n",
        "            The index of the decoder to be used.\n",
        "\n",
        "        Returns:\n",
        "        The computed ELBO value.\n",
        "        \"\"\"\n",
        "        q = self.encoder(x)  # Encode input into a latent distribution\n",
        "        z = q.rsample()  # Sample from the latent distribution using the reparameterization trick\n",
        "        decoder = self.decoders[decoder_idx]  # Select the corresponding decoder\n",
        "\n",
        "        elbo = torch.mean(\n",
        "            decoder(z).log_prob(x) - q.log_prob(z) + self.prior().log_prob(z)\n",
        "        )  # Compute ELBO using the likelihood, posterior, and prior\n",
        "\n",
        "        return elbo\n",
        "\n",
        "    def sample(self, decoder_idx, n_samples=1):\n",
        "        \"\"\"\n",
        "        Generate samples from the specified decoder.\n",
        "\n",
        "        Parameters:\n",
        "        decoder_idx: [int]\n",
        "            The index of the decoder to be used.\n",
        "        n_samples: [int, default=1]\n",
        "            The number of samples to generate.\n",
        "\n",
        "        Returns:\n",
        "        A batch of generated samples.\n",
        "        \"\"\"\n",
        "        z = self.prior().sample(torch.Size([n_samples]))  # Sample from the prior distribution\n",
        "        decoder = self.decoders[decoder_idx]  # Select the corresponding decoder\n",
        "        return decoder(z).sample()  # Generate samples from the decoder\n",
        "\n",
        "    def forward(self, x, decoder_idx):\n",
        "        \"\"\"\n",
        "        Compute the negative ELBO for optimization.\n",
        "\n",
        "        Parameters:\n",
        "        x: [torch.Tensor]\n",
        "            The input data tensor.\n",
        "        decoder_idx: [int]\n",
        "            The index of the decoder to be used.\n",
        "\n",
        "        Returns:\n",
        "        The negative ELBO value.\n",
        "        \"\"\"\n",
        "        return -self.elbo(x, decoder_idx)\n"
      ],
      "metadata": {
        "id": "qKI-kp2_2Kaj"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.Training vae\n"
      ],
      "metadata": {
        "id": "BGBEs4iMoT4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizers, data_loader, epochs, device):\n",
        "    num_decoders = len(model.decoders)\n",
        "    #total epoch should depende on the number of decoders\n",
        "    total_epochs = epochs * num_decoders\n",
        "    num_steps = len(data_loader) * total_epochs\n",
        "    epoch = 0\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    def noise(x, std=0.05):\n",
        "        eps = std * torch.randn_like(x)\n",
        "        return torch.clamp(x + eps, min=0.0, max=1.0)\n",
        "\n",
        "    with tqdm(range(num_steps)) as pbar:\n",
        "        for step in pbar:\n",
        "            try:\n",
        "                x = next(iter(data_loader))[0]\n",
        "                x = noise(x.to(device))\n",
        "                model=model\n",
        "                idx = torch.randint(0, num_decoders, (1,)).item()\n",
        "                #for each mini-batch of data, we randomly sample a decoder\n",
        "                #and take a gradient step to optimize the ELBO of  that decoder\n",
        "                # if we [1]\n",
        "                optimizer = optimizers[idx]\n",
        "                optimizer.zero_grad()\n",
        "                loss = model(x, decoder_idx=idx) #correspond to the changed part in VAE\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                loss_val = loss.detach().cpu().item()\n",
        "                losses.append(loss_val)\n",
        "\n",
        "                if step % 5 == 0:\n",
        "                    pbar.set_description(\n",
        "                        f\"epoch={epoch}, step={step}, decoder={idx}, loss={loss_val:.1f}\"\n",
        "                    )\n",
        "                if (step + 1) % len(data_loader) == 0:\n",
        "                    epoch += 1\n",
        "            except KeyboardInterrupt:\n",
        "                print(f\"Stopped at epoch {epoch}, step {step}, loss {loss_val:.1f}\")\n",
        "                break\n",
        "\n",
        "    return losses\n"
      ],
      "metadata": {
        "id": "ORvNA3H97nNp"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#because in part B we need 10 independent VAEs with  decoders 1,2,3, so I define a new train function\n",
        "#S is the number of the decoders\n",
        "def train_single_vae(seed, save_path, S, epochs_per_decoder):\n",
        "    set_seed(seed)\n",
        "    decoders = [GaussianDecoder(new_decoder()) for _ in range(S)]\n",
        "    #instantiating  S randomly initialized decoders\n",
        "    # note: set_seed(1001) only ensure the next time we run set_seed(1001), it's still the SAME randomly three decoders\n",
        "    # it will not destroy of the randomness of three different decoders\n",
        "    # [dd1,dd2,dd0]  [dd1,dd0,dd2]\n",
        "    encoder = GaussianEncoder(new_encoder())\n",
        "    prior = GaussianPrior(M)\n",
        "\n",
        "    model = VAE(prior, decoders, encoder).to(device)\n",
        "   # I just use the learning rate provided\n",
        "    optimizers = [\n",
        "        torch.optim.Adam(\n",
        "            list(model.encoder.parameters()) + list(decoder.parameters()), lr=1e-3\n",
        "        )\n",
        "        for decoder in model.decoders\n",
        "    ]\n",
        "\n",
        "    losses = train(model, optimizers, mnist_train_loader, epochs_per_decoder, device)\n",
        "\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    plt.figure()\n",
        "    plt.plot(range(5000, len(losses)), losses[5000:])\n",
        "    plt.xlabel(\"Iteration\")\n",
        "    plt.ylabel(\"ELBO Loss\")\n",
        "    plt.title(f\"Training Loss (Seed {seed}) [After 5000 Steps]\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path.replace(\".pt\", \"_loss.png\"))\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "DAYjbcQ05-xL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5 train 10 VAES"
      ],
      "metadata": {
        "id": "WcUldcuA2MxP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train 10 VAES with different decoder_counts,1,2,3"
      ],
      "metadata": {
        "id": "C21oFWuCz8Nb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I think this depends on how you implemented the retrainings.\n",
        "\n",
        "If you did something like :\n",
        "## Training:\n",
        "for each training run:\n",
        "    train model with max_number_of_decoders\n",
        "   10 independent vaes and 10 encoders\n",
        "## Geodesics\n",
        "for number_of_decoders in range(1,max_number_of_decoders):\n",
        "    compute_geodesics using number_of_decoders\n",
        "Resulting in 10 training runs, then the blue curve should be constant as the variation of the Euclidean distances should not vary.\n",
        "\n",
        "\n",
        "The difference is in whether you have 10 encoders\n",
        "\n",
        "We advise you to follow the first approach as it is computationally cheaper. But doing the second approach is by no means wrong."
      ],
      "metadata": {
        "id": "N_v-LUru9r52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#epochs_per_decoder=400\n",
        "#Q is num of vaes Q=10\n",
        "#according to TA's suggestion, I have changed to the first way to train\n",
        "def train_super_vae_models(Q=10, epochs_per_decoder=400, base_seed=1000, max_decoder_num=3):\n",
        "    folder = f\"experiments/vae_d{max_decoder_num}\"\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    for i in range(Q):\n",
        "        seed = base_seed + i\n",
        "        name = f\"vae_d{max_decoder_num}_seed{seed}\"\n",
        "        save_path = os.path.join(folder, f\"{name}.pt\")\n",
        "\n",
        "        print(f\"Training VAE: decoder={max_decoder_num}, seed={seed}\")\n",
        "        train_single_vae(seed, save_path, S=max_decoder_num, epochs_per_decoder=epochs_per_decoder)\n"
      ],
      "metadata": {
        "id": "thxtKogl6GGG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q is the number of VAES,here Q=2 epoch=2 just for testing the code.\n",
        "train_super_vae_models(Q=10, epochs_per_decoder=400, base_seed=1000,max_decoder_num=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "_LHu457k0GDI",
        "outputId": "f60cdbb8-2244-43c8-ba5d-3f89dc5b1ea1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training VAE: decoder=3, seed=1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/76800 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1739: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "epoch=6, step=440, decoder=1, loss=1007.7:   1%|          | 442/76800 [00:06<18:37, 68.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopped at epoch 6, step 442, loss 1212.2\n",
            "Training VAE: decoder=3, seed=1001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=2, step=165, decoder=0, loss=1951.1:   0%|          | 166/76800 [00:02<19:01, 67.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopped at epoch 2, step 166, loss 1951.1\n",
            "Training VAE: decoder=3, seed=1002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=1, step=110, decoder=0, loss=1885.4:   0%|          | 115/76800 [00:01<19:54, 64.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopped at epoch 1, step 115, loss 1775.3\n",
            "Training VAE: decoder=3, seed=1003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=6, step=420, decoder=1, loss=1495.9:   1%|          | 421/76800 [00:05<17:48, 71.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopped at epoch 6, step 421, loss 1495.9\n",
            "Training VAE: decoder=3, seed=1004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=0, step=60, decoder=1, loss=4768.8:   0%|          | 61/76800 [00:00<18:30, 69.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopped at epoch 0, step 61, loss 4768.8\n",
            "Training VAE: decoder=3, seed=1005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=0, step=0, decoder=0, loss=53521.2:   0%|          | 4/76800 [00:00<25:42, 49.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopped at epoch 0, step 4, loss 47139.5\n",
            "Training VAE: decoder=3, seed=1006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=5, step=370, decoder=0, loss=1787.2:   0%|          | 373/76800 [00:05<18:53, 67.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopped at epoch 5, step 373, loss 1659.5\n",
            "Training VAE: decoder=3, seed=1007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch=3, step=255, decoder=2, loss=1791.9:   0%|          | 259/76800 [00:03<17:50, 71.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopped at epoch 4, step 259, loss 1388.0\n",
            "Training VAE: decoder=3, seed=1008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/76800 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "cannot access local variable 'loss_val' where it is not associated with a value",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-db71084f37bd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizers, data_loader, epochs, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#correspond to the changed part in VAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-4e4ab29a33bb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, decoder_idx)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \"\"\"\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-4e4ab29a33bb>\u001b[0m in \u001b[0;36melbo\u001b[0;34m(self, x, decoder_idx)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \"\"\"\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Encode input into a latent distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Sample from the latent distribution using the reparameterization trick\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-b30b3b0d53a6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \"\"\"\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndependent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-b2daf621f716>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Q is the number of VAES,here Q=2 epoch=2 just for testing the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_super_vae_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_per_decoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_decoder_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-396659527a4a>\u001b[0m in \u001b[0;36mtrain_super_vae_models\u001b[0;34m(Q, epochs_per_decoder, base_seed, max_decoder_num)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training VAE: decoder={max_decoder_num}, seed={seed}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtrain_single_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_decoder_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_per_decoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs_per_decoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-0d6e690e4705>\u001b[0m in \u001b[0;36mtrain_single_vae\u001b[0;34m(seed, save_path, S, epochs_per_decoder)\u001b[0m\n\u001b[1;32m     20\u001b[0m     ]\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_per_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-db71084f37bd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizers, data_loader, epochs, device)\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Stopped at epoch {epoch}, step {step}, loss {loss_val:.1f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'loss_val' where it is not associated with a value"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_all_vaes(base_folder=\"experiments\", max_decoder_num=3, Q=10, base_seed=1000, device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
        "    all_models = {}\n",
        "\n",
        "    folder = os.path.join(base_folder, f\"vae_d{max_decoder_num}\")\n",
        "\n",
        "    for i in range(Q):\n",
        "        seed = base_seed + i\n",
        "        name = f\"vae_d{max_decoder_num}_seed{seed}\"\n",
        "        path = os.path.join(folder, f\"{name}.pt\")\n",
        "\n",
        "        # construct model structure\n",
        "        decoders = [GaussianDecoder(new_decoder()) for _ in range(max_decoder_num)]\n",
        "        encoder = GaussianEncoder(new_encoder())\n",
        "        prior = GaussianPrior(M=2)  # latent_dim = 2\n",
        "\n",
        "        model = VAE(prior, decoders, encoder).to(device)\n",
        "        model.load_state_dict(torch.load(path, map_location=device))\n",
        "        model.eval()\n",
        "\n",
        "        all_models[name] = model\n",
        "        print(f\"Loaded {name}\")\n",
        "\n",
        "    return all_models\n",
        "models = load_all_vaes()"
      ],
      "metadata": {
        "id": "ps_jve53nDOX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "7af3b659-0aad-4575-f734-f881b317be54"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded vae_d3_seed1000\n",
            "Loaded vae_d3_seed1001\n",
            "Loaded vae_d3_seed1002\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'experiments/vae_d3/vae_d3_seed1003.pt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-fc469779a9bd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mall_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_all_vaes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-fc469779a9bd>\u001b[0m in \u001b[0;36mload_all_vaes\u001b[0;34m(base_folder, max_decoder_num, Q, base_seed, device)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'experiments/vae_d3/vae_d3_seed1003.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#At convergence, we\n",
        "#have access to one encoder and Sdecoders.\n",
        "\n",
        "#for test\n",
        "\n",
        "# one model\n",
        "m = models[\"vae_d3_seed1001\"]\n",
        "encoder = m.encoder\n",
        "decoder0 = m.decoders[0]\n",
        "print(encoder)\n",
        "print(decoder0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oRHzb200mKG",
        "outputId": "b96127cc-d048-4e26-9e70-66e39f3c0270"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded vae_d3_seed1000\n",
            "Loaded vae_d3_seed1001\n",
            "GaussianEncoder(\n",
            "  (encoder_net): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): Softmax(dim=None)\n",
            "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (4): Softmax(dim=None)\n",
            "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (7): Flatten(start_dim=1, end_dim=-1)\n",
            "    (8): Linear(in_features=512, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "GaussianDecoder(\n",
            "  (decoder_net): Sequential(\n",
            "    (0): Linear(in_features=2, out_features=512, bias=True)\n",
            "    (1): Unflatten(dim=-1, unflattened_size=(32, 4, 4))\n",
            "    (2): Softmax(dim=None)\n",
            "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (5): Softmax(dim=None)\n",
            "    (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "    (8): Softmax(dim=None)\n",
            "    (9): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ConvTranspose2d(16, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 check vae quality"
      ],
      "metadata": {
        "id": "TRPm7LAoJHKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#5.2\n",
        "def visualize_all_vaes_all_decoders(models, test_loader, output_folder=\"vae_vis_outputs\", device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for name, model in models.items():\n",
        "        model.eval()\n",
        "        out_dir = os.path.join(output_folder, name)\n",
        "        os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "        num_decoders = len(model.decoders)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            data = next(iter(test_loader))[0].to(device)\n",
        "            z = model.encoder(data).mean\n",
        "\n",
        "            for decoder_idx in range(num_decoders):\n",
        "                # 1. Sampling\n",
        "                samples = model.sample(decoder_idx=decoder_idx, n_samples=64).cpu()\n",
        "                sample_path = os.path.join(out_dir, f\"samples_decoder{decoder_idx}.png\")\n",
        "                save_image(samples.view(64, 1, 28, 28), sample_path)\n",
        "\n",
        "                # 2. Reconstruction\n",
        "                recon = model.decoders[decoder_idx](z).mean\n",
        "                recon_path = os.path.join(out_dir, f\"reconstruction_decoder{decoder_idx}.png\")\n",
        "                save_image(torch.cat([data.cpu(), recon.cpu()], dim=0), recon_path)\n",
        "\n",
        "            print(f\" Saved all decoders for {name}\")\n"
      ],
      "metadata": {
        "id": "lFuV-aJ6JF-h"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "visualize_all_vaes_all_decoders(models, mnist_test_loader, output_folder=\"vae_vis_outputs\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOTzgtzaJY6o",
        "outputId": "8ef14e7d-fef9-454d-aa35-acf1f7c1cebe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Saved all decoders for vae_d3_seed1000\n",
            " Saved all decoders for vae_d3_seed1001\n",
            " Saved all decoders for vae_d3_seed1002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6 cruve and energy\n"
      ],
      "metadata": {
        "id": "Z7_VxVHhFZzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.1 cubiccurve T=64\n"
      ],
      "metadata": {
        "id": "j_8WxRNksmWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# page 68 cubiccurve(t) core code\n",
        "class CubicCurve(nn.Module):\n",
        "    def __init__(self, c0, c1):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        c0: torch.Tensor, start point (D,)\n",
        "        c1: torch.Tensor, end point (D,)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'  # Use GPU if available\n",
        "        self.T = 64  # Number of segments, typically in [64, 256]\n",
        "        self.D = c0.shape[0]  # Dimensionality of the curve\n",
        "\n",
        "        self.register_buffer(\"c0\", c0.to(self.device))  # Register start point as buffer (non-trainable)\n",
        "        self.register_buffer(\"c1\", c1.to(self.device))  # Register end point as buffer (non-trainable)\n",
        "\n",
        "        # Initialize intermediate control points along a straight line from c0 to c1\n",
        "        # This ensures the initial curve is linear before optimization\n",
        "        intermediate_points = torch.stack([\n",
        "            c0 + (c1 - c0) * (i + 1) / self.T  # Equally spaced points between c0 and c1\n",
        "            for i in range(self.T - 1)\n",
        "        ], dim=0).to(self.device)  # Shape: (T-1, D), stacked along the 0-th dimension\n",
        "\n",
        "        self.c_t = nn.Parameter(intermediate_points)  # Make intermediate points trainable\n",
        "\n",
        "        # Create a uniform grid of time values from 0 to 1 with (T + 1) points\n",
        "        self.register_buffer(\"t_grid\", torch.linspace(0, 1, self.T + 1, device=self.device))\n",
        "        # t0, t1, ..., tT\n",
        "\n",
        "    def forward(self, t):\n",
        "        \"\"\"\n",
        "        Compute the value of the piecewise linear curve at position t\n",
        "\n",
        "        Parameters:\n",
        "        t: torch.Tensor, shape (...,), range [0,1]\n",
        "\n",
        "        Returns:\n",
        "        torch.Tensor, shape (..., D)\n",
        "\n",
        "        Each segment is linearly interpolated between two control points:\n",
        "        Given control points p0 and p1, and a scalar alpha  [0, 1],\n",
        "        interpolation formula is: p(t) = (1 - alpha) * p0 + alpha * p1\n",
        "        where alpha = (t - t0) / (t1 - t0)\n",
        "        \"\"\"\n",
        "        t = t.to(self.device)  # Move t to the appropriate device\n",
        "\n",
        "        # Concatenate all control points: [c0, ..., c_t, ..., c1], shape (T+1, D)\n",
        "        control_points = torch.cat([self.c0.unsqueeze(0), self.c_t, self.c1.unsqueeze(0)], dim=0)\n",
        "        # unsqueeze(0) adds a new dimension at index 0: (D,)  (1, D)\n",
        "\n",
        "        # For each t, find the corresponding segment index in t_grid\n",
        "        # Example: t_grid = [0.0, 0.25, 0.5, 0.75, 1.0], t = 0.6  returns 3\n",
        "        # Even t = 0.5 returns 3 (right=True), then idx = 3 - 1 = 2\n",
        "\n",
        "        idx = torch.searchsorted(self.t_grid, t, right=True) - 1  # Get the left segment index\n",
        "        idx = idx.clamp(0, self.T - 1)  # Clamp idx to range [0, T - 1] to avoid overflow\n",
        "        # If idx == T, then idx + 1 is out of bounds, so clamp to T - 1\n",
        "\n",
        "        # Get start and end times of the segment\n",
        "        t0, t1 = self.t_grid[idx], self.t_grid[idx + 1]\n",
        "        # For example, t = 0.6  segment is [t2, t3] = [0.5, 0.75]\n",
        "\n",
        "        # Compute normalized position within the segment\n",
        "        alpha = (t - t0) / (t1 - t0)\n",
        "\n",
        "        # Get the corresponding control points for interpolation\n",
        "        ct0, ct1 = control_points[idx], control_points[idx + 1]\n",
        "\n",
        "        # Perform linear interpolation:\n",
        "        # p(t) = (1 - alpha) * c0 + alpha * c1\n",
        "        # Equivalent to:\n",
        "        # If t  [t_i, t_{i+1}]:\n",
        "        #     p(t) = c_i + (c_{i+1} - c_i) * (t - t_i) / (t_{i+1} - t_i)\n",
        "        #          = (1 - alpha) * c_i + alpha * c_{i+1}\n",
        "        return (1 - alpha.unsqueeze(-1)) * ct0 + alpha.unsqueeze(-1) * ct1  # (..., D), broadcast over last dim\n"
      ],
      "metadata": {
        "id": "V7r1Tut2FzsN"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.2 compute_energy\n",
        "\n",
        "$$\n",
        "\\mathcal{E}[\\gamma] \\approx \\sum_{t=0}^{T-1} \\mathbb{E}_{\\theta, \\theta' \\sim q(\\theta) q(\\theta)}\n",
        "\\left[ \\left\\| f_{\\theta} (\\gamma(t + \\frac{1}{T})) - f_{\\theta'} (\\gamma(t / T)) \\right\\|^2 \\right]\n",
        "$$\n",
        "\n",
        "$f_{\\theta}$ $f_{\\theta'}$ denotes deoder ensemble members drawn uniformly"
      ],
      "metadata": {
        "id": "FuBRA6srsq2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_curve_energy(curve, decoders, T, fixed_indices=None, device='cuda'):\n",
        "    \"\"\"\n",
        "    Compute the energy of a curve using fixed decoder indices (no Monte Carlo).\n",
        "\n",
        "    Parameters:\n",
        "    - curve: An instance of CubicCurve\n",
        "    - decoders: List of decoder modules\n",
        "    - T: Number of time steps\n",
        "    - fixed_indices: Pre-fixed decoder indices [(idx1_t0, idx2_t0), (idx1_t1, idx2_t1), ...]\n",
        "    - device: Computing device\n",
        "\n",
        "    Returns:\n",
        "    - Scalar energy value\n",
        "    \"\"\"\n",
        "    total_energy = 0.0  # Accumulate energy over all time steps\n",
        "\n",
        "    for i in range(T):\n",
        "        t0 = torch.tensor([i / T], device=device, dtype=torch.float32)\n",
        "        t1 = torch.tensor([(i + 1) / T], device=device, dtype=torch.float32)\n",
        "\n",
        "        x0 = curve(t0)  # (t0), shape [1, D]\n",
        "        x1 = curve(t1)  # (t1), shape [1, D]\n",
        "\n",
        "        # Get fixed decoder indices for this segment\n",
        "        idx1, idx2 = fixed_indices[i]\n",
        "        #why i don't write this\n",
        "        # idx1,idx2=random(./)\n",
        "        # Compute decoder outputs at t0 and t1\n",
        "        y0 = decoders[idx1](x0).mean\n",
        "        y1 = decoders[idx2](x1).mean\n",
        "        #You must implement an algorithm to compute geodesics under the pull-back metric\n",
        "#associated with the mean of the Gaussian decoder.\n",
        "        # Energy = L2 norm between decoded outputs\n",
        "        energy = torch.norm(y1 - y0, p=2)\n",
        "\n",
        "        total_energy += energy\n",
        "\n",
        "    return total_energy"
      ],
      "metadata": {
        "id": "L1ntkmnPoo0g"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.3 optimize_geodesics"
      ],
      "metadata": {
        "id": "6e6UxF2PO3Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_geodesic(c0, c1, decoders, T, steps, lr, device,\n",
        "                      early_stopping_n, early_stopping_delta):\n",
        "    \"\"\"\n",
        "    Optimize a geodesic curve while ensuring the objective function remains unchanged during optimization.\n",
        "\n",
        "    Parameters:\n",
        "    - c0: Starting point\n",
        "    - c1: Endpoint\n",
        "    - decoders: List of decoder modules\n",
        "    - T: Number of time steps\n",
        "    - steps: Number of optimization iterations\n",
        "    - lr: Learning rate\n",
        "    - device: Computing device\n",
        "    - early_stopping_n: Number of steps to check for early stopping\n",
        "    - early_stopping_delta: Minimum required improvement to continue\n",
        "\n",
        "    Returns:\n",
        "    - Optimized curve\n",
        "    - Logged energy values\n",
        "    \"\"\"\n",
        "    curve = CubicCurve(c0, c1).to(device)\n",
        "    optimizer = torch.optim.Adam(curve.parameters(), lr=lr)\n",
        "\n",
        "    # \n",
        "    # min represent we are minimizing the data\n",
        "    #factor - after the I also added a `torch.optim.lr_scheduler.ReduceLROnPlateau`,\n",
        "    #which reduces the learning rate by a factor of 0.5 if the change is less than 1e-3 within 100 steps,\n",
        "    # if the change is less than 1e-3 within 300 steps, early stopping is triggered. Of course,\n",
        "    # this is just based on experience.I set 2000steps and its very slow.\n",
        "    #I  dont think my method is good.\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode='min',\n",
        "        factor=0.5,\n",
        "        patience=100,\n",
        "        threshold=1e-3,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    energy_log = []\n",
        "\n",
        "    #generate inside the function but not inside the optimization loop\n",
        "    fixed_indices = [(torch.randint(0, len(decoders), (1,), device=device).item(),\n",
        "                      torch.randint(0, len(decoders), (1,), device=device).item())\n",
        "                     for _ in range(T)]\n",
        "\n",
        "    best_energy = float('inf')\n",
        "    no_improve_count = 0\n",
        "\n",
        "    with tqdm(range(steps)) as pbar:\n",
        "        for step in pbar:\n",
        "            optimizer.zero_grad()\n",
        "            energy = compute_curve_energy(curve, decoders, T=T, fixed_indices=fixed_indices, device=device)\n",
        "            energy.backward()\n",
        "            optimizer.step()\n",
        "            current_lr = optimizer.param_groups[0]['lr']\n",
        "            #  energy  scheduler\n",
        "            energy_value = energy.item()\n",
        "            scheduler.step(energy_value)\n",
        "            energy_log.append(energy_value)\n",
        "\n",
        "            # Early Stopping step >= 300 \n",
        "            if step >= 300:\n",
        "                if energy_value < best_energy - early_stopping_delta:\n",
        "                    best_energy = energy_value\n",
        "                    no_improve_count = 0\n",
        "                else:\n",
        "                    no_improve_count += 1\n",
        "\n",
        "                if no_improve_count >= early_stopping_n:\n",
        "                    print(f\"Early stopping at step {step}, energy: {energy_value:.6f}, LR: {current_lr:.2e}\")\n",
        "                    break\n",
        "\n",
        "            pbar.set_description(f\"Energy: {energy_value:.6f}, LR: {current_lr:.2e}\")\n",
        "\n",
        "    return curve, energy_log\n"
      ],
      "metadata": {
        "id": "JqEQ2nKLotZb"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 10random latent_varibale pairs\n"
      ],
      "metadata": {
        "id": "LE52pKwas5TJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7.1 data preparation"
      ],
      "metadata": {
        "id": "uKh_3_IruXFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== Extract all images from the test set ======\n",
        "all_test_x = []\n",
        "all_test_y = []\n",
        "for x, y in mnist_test_loader:\n",
        "    all_test_x.append(x)\n",
        "    all_test_y.append(y)\n",
        "\n",
        "all_test_x = torch.cat(all_test_x, dim=0)  # shape: [N, 1, 28, 28]\n",
        "all_test_y = torch.cat(all_test_y, dim=0)  # shape: [N]\n",
        "\n",
        "# ====== random seed3 :to ensure everyone  get the same test points 1 global 2 vae  ======\n",
        "random.seed(42) #very important!\n",
        "\n",
        "# ====== Sample 10 image pairs ==here is a way to split the work, one 2-3 pairs====\n",
        "num_pairs = 10 #10\n",
        "N = all_test_x.shape[0] #total number of test points\n",
        "indices = random.sample(range(N), 2 * num_pairs) #from this take 20 pair images\n",
        "\n",
        "# ====== Construct image pair list: [(x_i, x_j), ...] ======\n",
        "test_image_pairs = [\n",
        "    (all_test_x[indices[i]], all_test_x[indices[i + 1]])\n",
        "    for i in range(0, 2 * num_pairs, 2)\n",
        "]  # Each element shape: ([1, 28, 28], [1, 28, 28]) [0,1][2,3][4,5])\n",
        "# let (yi,yj ) denote a fixed pair of test points (these should be the same across different models)"
      ],
      "metadata": {
        "id": "u66xdqOMJYLB"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7.2 geodesic_distances"
      ],
      "metadata": {
        "id": "bSY9QZwW2FJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "x1 = x1.unsqueeze(0)  # Convert x1 to shape [1, C, H, W] as a batch input\n",
        "# Models usually expect batched input, even for a single image\n",
        "\n",
        "posterior = model.encoder(x1)  # Pass the image through the VAE encoder, returns a distribution object\n",
        "\n",
        "z = posterior.base_dist.loc  # Get the mean vector from the underlying distribution (usually Normal(mean, std))\n",
        "\n",
        "z = z.squeeze(0)  # Remove the batch dimension: [1, latent_dim]  [latent_dim]\n"
      ],
      "metadata": {
        "id": "ySLBgMGFg2IT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pair_idxpair_idx3decodervae,"
      ],
      "metadata": {
        "id": "_EqZKr61Y1A-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# This logic is quite tricky and must be understood carefully. GPT might directly give a wrong answer.\n",
        "# Suppose the number of decoders is 2.\n",
        "# For a given data pair, we need to evaluate it using different VAEs. The way we compute is to treat it as a 2-decoder VAE\n",
        "# (even though it may have been trained with 3 decoders originally, we treat it as having only 2 decoders).\n",
        "# We can, for instance, take the same index set (e.g., 1,2) for all VAEs. Since each VAE is different, fixing indices 1,2 or sampling them randomly makes no difference.\n",
        "# The decoder indices 1,2 from VAE1 and 2,3 from VAE2 are equally randomjust random selections.\n",
        "# Therefore, the hash function and the M-VAE index can be either related or unrelatedit doesnt matter. To be extra safe, they can be related.\n",
        "# But can they be related to pair_idx?\n",
        "# That is, can we, for example, assign the same VAE to all data pairs, and for the first pair use decoder indices 1,2, for the second pair 2,3, etc.?\n",
        "# I believe this is not allowed. Because if we do this over 10 data pairs, its as if the VAE has 3 decoders again!\n",
        "# What we actually want to evaluate is a VAE with only 2 decoders (fixed for the whole dataset).\n",
        "# So, it absolutely must not depend on pair_idx.\n",
        "# Regarding the outer loop: whether the number of decoders is 1 or 2, using the same random seed or not has no effect.\n",
        "# Because decoder1 selects 1 index, and decoder2 selects 2 indicesdifferent amounts of data.\n",
        "# Moreover, even if theres some relationshipe.g., decoder1 selects index 1, decoder2 selects indices 1,2, or decoder1 selects 2, and decoder2 selects 2,3\n",
        "# This doesnt work either. If it happens to be the same VAE, then having two decoders is always more powerful than one.\n",
        "# Since we are comparing the performance difference between 1 and 2 decoders, these selections must be independent.\n",
        "```"
      ],
      "metadata": {
        "id": "aZRgteRMkqF7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, about random seed sampling. First of all, can it be placed inside the optimization loop? Absolutely not!  \n",
        "If so, for the same VAE and different data points, the sampling during each optimization would be the same in the for i_T loopmaking the objective function exactly the same.  \n",
        "This weakens the effect of having 10 different data points. Moreover, the calculation is originally based on an expectationthose 10 points effectively perform 10 rounds of Monte Carlo sampling.  \n",
        "So the hash function must depend on the data point. Each data points sampling must be independent.\n",
        "\n",
        "Next, regarding the VAE: since the VAEs are independent, whether to fix the decoder choice per optimization or not doesnt matter. To be conservative, we do fix it.\n",
        "\n",
        "Finally, regarding the decoder count: same logic as beforeits best to make them independent.  \n",
        "If decoder count 1 and 2 are correlated, then decoder1 and decoder2 might differ not just in the number of decoders, but because decoder2 includes more powerful decoders.  \n",
        "We want to isolate the effect of decoder count alone, so they must be sampled independently.\n"
      ],
      "metadata": {
        "id": "gbdnj85ctN5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_all_geodesic_distances(models_dict, test_image_pairs, max_decoder_num, device, T, steps, lr, num_vaes, early_stopping_n,early_stopping_delta):\n",
        "    distances = []  # Outer: num_decoders - 1  Middle: pair_idx  Inner: energy list from all VAEs\n",
        "\n",
        "    for number_of_decoders in range(1, max_decoder_num + 1):\n",
        "        pair_results = []  #  pair \n",
        "\n",
        "        for pair_idx, (x1, x2) in enumerate(test_image_pairs):\n",
        "            vae_energies = []  #  pair vae \n",
        "\n",
        "            for m in range(num_vaes):\n",
        "                model_name = f\"vae_d{max_decoder_num}_seed{1000 + m}\"\n",
        "                model = models_dict[model_name]\n",
        "                model.eval()\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    z1 = model.encoder(x1.unsqueeze(0).to(device)).base_dist.loc.squeeze(0)\n",
        "                    z2 = model.encoder(x2.unsqueeze(0).to(device)).base_dist.loc.squeeze(0)\n",
        "\n",
        "                result_dir = f\"results_geodesic/decoders_{number_of_decoders}/pair_{pair_idx}/vae_{m}\"\n",
        "                os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "                curve_path = os.path.join(result_dir, \"curve.pt\")\n",
        "                energy_log_path = os.path.join(result_dir, \"energy_log.pt\")\n",
        "\n",
        "                if os.path.exists(curve_path) and os.path.exists(energy_log_path):\n",
        "                    curve = torch.load(curve_path, map_location=device, weights_only=False)\n",
        "                    energy_log = torch.load(energy_log_path, map_location=device, weights_only=False)\n",
        "                    print(f\" Loaded: decoders={number_of_decoders}, pair={pair_idx}, vae={m}\")\n",
        "                else:\n",
        "                    seed_dec = hash((\"decoder_select\", m, number_of_decoders)) % (2**32)\n",
        "                    random.seed(seed_dec)\n",
        "                    selected_decoders = random.sample(list(model.decoders), number_of_decoders)\n",
        "\n",
        "                    seed_fixed = hash((\"fixed_indices\", m, pair_idx, number_of_decoders)) % (2**32)\n",
        "                    torch.manual_seed(seed_fixed)\n",
        "\n",
        "                    curve, energy_log = optimize_geodesic(\n",
        "                        z1, z2, decoders=selected_decoders, T=T, steps=steps, lr=lr, device=device,\n",
        "                        early_stopping_n=early_stopping_n, early_stopping_delta=early_stopping_delta\n",
        "                    )\n",
        "\n",
        "                    torch.save(curve, curve_path)\n",
        "                    torch.save(energy_log, energy_log_path)\n",
        "                    print(f\" Computed & saved: decoders={number_of_decoders}, pair={pair_idx}, vae={m}\")\n",
        "\n",
        "                energy = energy_log[-1]#\n",
        "                vae_energies.append(energy)\n",
        "\n",
        "            pair_results.append(vae_energies)\n",
        "\n",
        "        distances.append(pair_results)\n",
        "\n",
        "    return distances\n"
      ],
      "metadata": {
        "id": "OeH2LbBXuVXY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "T = 64 # this T is not the same  as the total segmentation\n",
        "steps = 1500 #optimization step ,\n",
        "lr = 5*1e-2 #learning rate\n",
        "num_vaes = 10 #required 10\n",
        "max_decoder_num = 3\n",
        "early_stopping_n=300\n",
        "early_stopping_delta=1e-3\n",
        "\n",
        "geodesic_distances = compute_all_geodesic_distances(\n",
        "    models_dict=models,\n",
        "    test_image_pairs=test_image_pairs,\n",
        "    max_decoder_num=max_decoder_num,\n",
        "    device=device,\n",
        "    T=T,\n",
        "    steps=steps,\n",
        "    lr=lr,\n",
        "    num_vaes=num_vaes,\n",
        "    early_stopping_n=early_stopping_n,\n",
        "    early_stopping_delta=early_stopping_delta\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk_T7IBp2AU8",
        "outputId": "bb6db74f-76c3-4166-9580-493550452fd3"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1739: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "Energy: 15.840173, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 43.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=1, pair=0, vae=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 17.470350, LR: 2.50e-02: 100%|| 200/200 [00:04<00:00, 41.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=1, pair=0, vae=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 12.319338, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 43.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=1, pair=0, vae=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 4.154807, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 42.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=1, pair=1, vae=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 3.779039, LR: 2.50e-02: 100%|| 200/200 [00:04<00:00, 42.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=1, pair=1, vae=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 3.026183, LR: 2.50e-02: 100%|| 200/200 [00:04<00:00, 43.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=1, pair=1, vae=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 13.406573, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 42.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=1, pair=2, vae=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 12.854430, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 43.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=1, pair=2, vae=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 15.587112, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 41.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=1, pair=2, vae=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 17.585930, LR: 2.50e-02: 100%|| 200/200 [00:04<00:00, 43.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=2, pair=0, vae=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 22.350105, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 42.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=2, pair=0, vae=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 17.005510, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 42.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=2, pair=0, vae=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 4.820918, LR: 2.50e-02: 100%|| 200/200 [00:04<00:00, 43.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=2, pair=1, vae=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 5.464211, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 41.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=2, pair=1, vae=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 3.306560, LR: 2.50e-02: 100%|| 200/200 [00:04<00:00, 43.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=2, pair=1, vae=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 15.589498, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 41.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=2, pair=2, vae=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 15.940869, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 44.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=2, pair=2, vae=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 19.035770, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 41.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=2, pair=2, vae=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 14.577441, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 41.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=3, pair=0, vae=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 16.982512, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 42.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=3, pair=0, vae=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 17.479891, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 40.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=3, pair=0, vae=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 6.058682, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 42.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=3, pair=1, vae=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 5.707486, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 41.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=3, pair=1, vae=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 4.476087, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 42.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=3, pair=1, vae=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 19.022999, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 41.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=3, pair=2, vae=0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 18.751144, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 42.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=3, pair=2, vae=1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Energy: 19.404316, LR: 5.00e-02: 100%|| 200/200 [00:04<00:00, 41.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=3, pair=2, vae=2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#\n",
        "def sqrt_nested_distances(distances):\n",
        "    return [\n",
        "        [  # decoder_idx \n",
        "            [np.sqrt(d) for d in vae_dists]  #  vae \n",
        "            for vae_dists in pair_list       #  pair\n",
        "        ]\n",
        "        for pair_list in distances           #  decoder_num\n",
        "    ]\n"
      ],
      "metadata": {
        "id": "Q1WER8-gXOl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "geodesic_distances = sqrt_nested_distances(geodesic_distances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gyoi6RXkLTB6",
        "outputId": "de13dfea-7007-4324-a612-76d7a69a9185"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[15.84017276763916, 17.47035026550293, 12.319337844848633],\n",
              "  [4.154807090759277, 3.7790393829345703, 3.0261828899383545],\n",
              "  [13.406573295593262, 12.854430198669434, 15.587112426757812]],\n",
              " [[17.58592987060547, 22.35010528564453, 17.005510330200195],\n",
              "  [4.82091760635376, 5.4642109870910645, 3.3065595626831055],\n",
              "  [15.589497566223145, 15.940869331359863, 19.035770416259766]],\n",
              " [[14.577441215515137, 16.982511520385742, 17.479890823364258],\n",
              "  [6.058681964874268, 5.707486152648926, 4.4760870933532715],\n",
              "  [19.022998809814453, 18.751144409179688, 19.404315948486328]]]"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "if os.path.exists(\"results_geodesic\"):\n",
        "    shutil.rmtree(\"results_geodesic\")\n"
      ],
      "metadata": {
        "id": "lP4e6Ep55LGB"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.3 energy log plot"
      ],
      "metadata": {
        "id": "VCqeSyz7cPU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_all_energy_logs(max_decoder_num, num_pairs, num_vaes, root='results_geodesic', out_root='energy_plots'):\n",
        "    for n in range(1, max_decoder_num + 1):\n",
        "        for pair_idx in range(num_pairs):\n",
        "            for m in range(num_vaes):\n",
        "                log_path = f\"{root}/decoders_{n}/pair_{pair_idx}/vae_{m}/energy_log.pt\"\n",
        "                if not os.path.exists(log_path):\n",
        "                    print(f\" Missing: {log_path}\")\n",
        "                    continue\n",
        "\n",
        "                #  energy_log\n",
        "                energy_log = torch.load(log_path)\n",
        "\n",
        "                # \n",
        "                save_dir = f\"{out_root}/decoders_{n}/pair_{pair_idx}/vae_{m}\"\n",
        "                os.makedirs(save_dir, exist_ok=True)\n",
        "                save_path = os.path.join(save_dir, \"energy.png\")\n",
        "\n",
        "                # \n",
        "                plt.figure()\n",
        "                plt.plot(energy_log)\n",
        "                plt.xlabel(\"Optimization Step\")\n",
        "                plt.ylabel(\"Energy\")\n",
        "                plt.title(f\"Decoders={n}, Pair={pair_idx}, VAE={m}\")\n",
        "                plt.grid(True)\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(save_path)\n",
        "                plt.close()\n",
        "\n",
        "                print(f\" Saved: {save_path}\")\n"
      ],
      "metadata": {
        "id": "GrY1hoct6gKE"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_all_energy_logs(max_decoder_num=3, num_pairs=10, num_vaes=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXEbQQTS6kzM",
        "outputId": "6cd801ce-6331-4584-cd0f-731f554a19bd"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Saved: energy_plots/decoders_1/pair_0/vae_0/energy.png\n",
            " Saved: energy_plots/decoders_1/pair_0/vae_1/energy.png\n",
            " Saved: energy_plots/decoders_1/pair_0/vae_2/energy.png\n",
            " Saved: energy_plots/decoders_1/pair_1/vae_0/energy.png\n",
            " Saved: energy_plots/decoders_1/pair_1/vae_1/energy.png\n",
            " Saved: energy_plots/decoders_1/pair_1/vae_2/energy.png\n",
            " Saved: energy_plots/decoders_1/pair_2/vae_0/energy.png\n",
            " Saved: energy_plots/decoders_1/pair_2/vae_1/energy.png\n",
            " Saved: energy_plots/decoders_1/pair_2/vae_2/energy.png\n",
            " Saved: energy_plots/decoders_2/pair_0/vae_0/energy.png\n",
            " Saved: energy_plots/decoders_2/pair_0/vae_1/energy.png\n",
            " Saved: energy_plots/decoders_2/pair_0/vae_2/energy.png\n",
            " Saved: energy_plots/decoders_2/pair_1/vae_0/energy.png\n",
            " Saved: energy_plots/decoders_2/pair_1/vae_1/energy.png\n",
            " Saved: energy_plots/decoders_2/pair_1/vae_2/energy.png\n",
            " Saved: energy_plots/decoders_2/pair_2/vae_0/energy.png\n",
            " Saved: energy_plots/decoders_2/pair_2/vae_1/energy.png\n",
            " Saved: energy_plots/decoders_2/pair_2/vae_2/energy.png\n",
            " Saved: energy_plots/decoders_3/pair_0/vae_0/energy.png\n",
            " Saved: energy_plots/decoders_3/pair_0/vae_1/energy.png\n",
            " Saved: energy_plots/decoders_3/pair_0/vae_2/energy.png\n",
            " Saved: energy_plots/decoders_3/pair_1/vae_0/energy.png\n",
            " Saved: energy_plots/decoders_3/pair_1/vae_1/energy.png\n",
            " Saved: energy_plots/decoders_3/pair_1/vae_2/energy.png\n",
            " Saved: energy_plots/decoders_3/pair_2/vae_0/energy.png\n",
            " Saved: energy_plots/decoders_3/pair_2/vae_1/energy.png\n",
            " Saved: energy_plots/decoders_3/pair_2/vae_2/energy.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "if os.path.exists(\"results_geodesic\"):\n",
        "    shutil.rmtree(\"results_geodesic\")\n",
        "\n"
      ],
      "metadata": {
        "id": "2QJL_g3-9S1u"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7.4 geodesics plot not relevant to this task,alough helpful to task1\n"
      ],
      "metadata": {
        "id": "59KiRvyAcSmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#7.3 energy log plot"
      ],
      "metadata": {
        "id": "xbDoZhzAcLsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.1 Euclidean Distances"
      ],
      "metadata": {
        "id": "mIDjaq0Y2Kmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_all_euclidean_distances(models_dict, test_image_pairs, max_decoder_num=3, num_vaes=10):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    distances = []  # [decoder_num - 1][pair_idx][vae_idx]\n",
        "\n",
        "    for number_of_decoders in range(1, max_decoder_num + 1):\n",
        "        pair_results = []\n",
        "\n",
        "        for pair_idx, (x1, x2) in enumerate(test_image_pairs):\n",
        "            vae_results = []\n",
        "\n",
        "            for m in range(num_vaes):\n",
        "                model_name = f\"vae_d{max_decoder_num}_seed{1000 + m}\"\n",
        "                model = models_dict[model_name]\n",
        "                model.eval()\n",
        "\n",
        "                result_dir = f\"results_euclidean/decoders_{number_of_decoders}/pair_{pair_idx}/vae_{m}\"\n",
        "                os.makedirs(result_dir, exist_ok=True)\n",
        "                dist_path = os.path.join(result_dir, \"euclidean.pt\")\n",
        "\n",
        "                if os.path.exists(dist_path):\n",
        "                    euclidean = torch.load(dist_path,map_location=device,weights_only=False)\n",
        "                    print(f\" Loaded: decoders={number_of_decoders}, pair={pair_idx}, vae={m}\")\n",
        "                else:\n",
        "                    with torch.no_grad():\n",
        "                        z1 = model.encoder(x1.unsqueeze(0).to(device)).base_dist.loc.squeeze(0)\n",
        "                        z2 = model.encoder(x2.unsqueeze(0).to(device)).base_dist.loc.squeeze(0)\n",
        "\n",
        "                    euclidean = torch.norm(z1 - z2, p=2).item()#\n",
        "                    torch.save(euclidean, dist_path)\n",
        "                    print(f\" Computed & saved: decoders={number_of_decoders}, pair={pair_idx}, vae={m}\")\n",
        "\n",
        "                vae_results.append(euclidean)\n",
        "\n",
        "            pair_results.append(vae_results)\n",
        "\n",
        "        distances.append(pair_results)\n",
        "\n",
        "    return distances\n"
      ],
      "metadata": {
        "id": "hlwCJ3-p2So0"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "euclidean_distances = compute_all_euclidean_distances(\n",
        "    models_dict=models,\n",
        "    test_image_pairs=test_image_pairs,\n",
        "    max_decoder_num=3,\n",
        "    num_vaes=10\n",
        ")\n",
        "#test_image_pairs = [\n",
        "    #(all_test_x[indices[i]], all_test_x[indices[i + 1]])\n",
        "    #for i in range(0, 2 * num_pairs, 2)\n",
        "#]  10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcDEKDuw2Twr",
        "outputId": "d6c1ebf3-5684-4a03-a2fd-56708a72cd00"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Computed & saved: decoders=1, pair=0, vae=0\n",
            " Computed & saved: decoders=1, pair=0, vae=1\n",
            " Computed & saved: decoders=1, pair=0, vae=2\n",
            " Computed & saved: decoders=1, pair=1, vae=0\n",
            " Computed & saved: decoders=1, pair=1, vae=1\n",
            " Computed & saved: decoders=1, pair=1, vae=2\n",
            " Computed & saved: decoders=1, pair=2, vae=0\n",
            " Computed & saved: decoders=1, pair=2, vae=1\n",
            " Computed & saved: decoders=1, pair=2, vae=2\n",
            " Computed & saved: decoders=2, pair=0, vae=0\n",
            " Computed & saved: decoders=2, pair=0, vae=1\n",
            " Computed & saved: decoders=2, pair=0, vae=2\n",
            " Computed & saved: decoders=2, pair=1, vae=0\n",
            " Computed & saved: decoders=2, pair=1, vae=1\n",
            " Computed & saved: decoders=2, pair=1, vae=2\n",
            " Computed & saved: decoders=2, pair=2, vae=0\n",
            " Computed & saved: decoders=2, pair=2, vae=1\n",
            " Computed & saved: decoders=2, pair=2, vae=2\n",
            " Computed & saved: decoders=3, pair=0, vae=0\n",
            " Computed & saved: decoders=3, pair=0, vae=1\n",
            " Computed & saved: decoders=3, pair=0, vae=2\n",
            " Computed & saved: decoders=3, pair=1, vae=0\n",
            " Computed & saved: decoders=3, pair=1, vae=1\n",
            " Computed & saved: decoders=3, pair=1, vae=2\n",
            " Computed & saved: decoders=3, pair=2, vae=0\n",
            " Computed & saved: decoders=3, pair=2, vae=1\n",
            " Computed & saved: decoders=3, pair=2, vae=2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "euclidean_distances"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNmB38ASP0_p",
        "outputId": "27874a1a-a379-40b7-d8a9-b627cbbd9554"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[4.804272651672363, 4.759725093841553, 4.026854038238525],\n",
              "  [0.97257000207901, 0.9008387923240662, 0.7701483368873596],\n",
              "  [5.820830345153809, 4.815484523773193, 5.016952991485596]],\n",
              " [[4.804272651672363, 4.759725093841553, 4.026854038238525],\n",
              "  [0.97257000207901, 0.9008387923240662, 0.7701483368873596],\n",
              "  [5.820830345153809, 4.815484523773193, 5.016952991485596]],\n",
              " [[4.804272651672363, 4.759725093841553, 4.026854038238525],\n",
              "  [0.97257000207901, 0.9008387923240662, 0.7701483368873596],\n",
              "  [5.820830345153809, 4.815484523773193, 5.016952991485596]]]"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "if os.path.exists(\"results_euclidean\"):\n",
        "    shutil.rmtree(\"results_euclidean\")\n",
        "\n"
      ],
      "metadata": {
        "id": "AhGKPtNn9bBU"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.2  compute Average Cov~num of decoders (both the geodesics and Euclidean) # i forget to take sqrt"
      ],
      "metadata": {
        "id": "xZhZSP5R2aB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_avg_covs_across_pairs(distances):\n",
        "    avg_covs = []\n",
        "    decoder_indices = []\n",
        "    # distances == [decoder_num - 1][pair_idx][vae_idx]\n",
        "\n",
        "    for decoder_idx, all_pairs in enumerate(distances):  # Outer loop over decoder count\n",
        "        covs = []  # covs[1]: cov_ij for the first test point, covs[2]: for the second, etc.\n",
        "\n",
        "        for vae_dists in all_pairs:  # [pair_idx][vae_idx], all_pairs[1] = first test point\n",
        "            d = np.array(vae_dists)\n",
        "            mean = np.mean(d)  # Mean across 10 VAEs\n",
        "            std = np.std(d)    # Std across 10 VAEs\n",
        "\n",
        "            if mean > 0:\n",
        "                cov = std / mean  # Compute cov_ij for the current test point\n",
        "                covs.append(cov)  # Append current test point's cov_ij to covs list\n",
        "\n",
        "        avg_cov = np.mean(covs)  # Average cov_ij over 10 test points\n",
        "        avg_covs.append(avg_cov)  # Append to avg_covs list for the current decoder count\n",
        "        decoder_indices.append(decoder_idx + 1)  # Decoder count starts from 1\n",
        "\n",
        "    return avg_covs, decoder_indices\n"
      ],
      "metadata": {
        "id": "kHBE_u-g2laX"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "geodesic_avg_covs, decoder_counts = compute_avg_covs_across_pairs(geodesic_distances)\n",
        "euclidean_avg_covs, _ = compute_avg_covs_across_pairs(euclidean_distances)"
      ],
      "metadata": {
        "id": "m1Qq9vho2pFi"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_and_save_avg_cov(geodesic_avg_covs, euclidean_avg_covs, decoder_counts, save_path=\"final_plots/avg_cov_vs_decoders.png\"):\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(decoder_counts, geodesic_avg_covs, marker='o', label='Geodesic distance')\n",
        "    plt.plot(decoder_counts, euclidean_avg_covs, marker='o', label='Euclidean distance')\n",
        "    plt.xlabel('Number of ensemble decoders')\n",
        "    plt.ylabel('Average Coefficient of Variation (CoV)')\n",
        "    plt.title('Average CoV vs. Number of Ensemble Decoders')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "    plt.savefig(save_path)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "aZc3_qVn2qtb"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_and_save_avg_cov(geodesic_avg_covs, euclidean_avg_covs, decoder_counts)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "yM0RTYY6BwGy",
        "outputId": "8587f37c-94ed-4c4d-f19f-cc3c23b424e0"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "#  /content \n",
        "shutil.make_archive('figure2', 'zip', '/content')\n",
        "\n",
        "# \n",
        "files.download('figure2.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "kXrPlNuUSsx1",
        "outputId": "8a8997f5-4152-42e6-8669-5c49b09ec3a5"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_535fe1b2-60a2-4af6-8470-8424c5c2b085\", \"figure2.zip\", 25957883)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}